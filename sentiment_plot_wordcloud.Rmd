```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r, eval=FALSE}
library(twitteR)
library(ROAuth)

# authenticate with Twitter

# DON'T UPLOAD THE KEYS ON GITHUB, AS THIS IS PUBLIC REPO
consumerKey<-	"XXX"
consumerSecret<-"XXX"

accessToken<-"XXX"
accessSecret<-"XXX"


setup_twitter_oauth (consumerKey, consumerSecret, accessToken, accessSecret)  # authenticate

# search for tweets by keyword

tweets<-searchTwitter("muslim", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_muslim<-twListToDF(tweets)

tweets<-searchTwitter("islam", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_islam<-twListToDF(tweets)

tweets<-searchTwitter("arab", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_arab<-twListToDF(tweets)

tweets<-searchTwitter("muhammad", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_muhammad<-twListToDF(tweets)

all_muslim_tweets <- rbind(tweets_muslim, tweets_islam, tweets_arab, tweets_muhammad)
# write out to a CSV file
write.csv(all_muslim_tweets, file="muslim_tweets.csv")

```


```{r, eval=FALSE}
library(twitteR)
library(ROAuth)

# search for tweets by keyword

tweets<-searchTwitter("christian", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_christian<-twListToDF(tweets)

tweets<-searchTwitter("christ", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_christ<-twListToDF(tweets)

tweets<-searchTwitter("catholic", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_catholic<-twListToDF(tweets)

tweets<-searchTwitter("church", n=1000, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL,
                                resultType=NULL, retryOnRateLimit=120)
# put tweets in a data frame
tweets_church<-twListToDF(tweets)

all_christian_tweets <- rbind(tweets_christian, tweets_christ, tweets_catholic, tweets_church)
# write out to a CSV file
write.csv(all_christian_tweets, file="christian_tweets.csv")

```

# Cleaning

```{r, eval= FALSE, message=FALSE}
library(syuzhet)
library(plotly)
library(tm)
library(wordcloud)

#import your dataset to analyse, 
#ensure it is in the same directory as your code, 
#otherwise you need to add the path
  
tweets <- read.csv("muslim_tweets.csv")
  clean_tweets = tweets$text
  
  print(length(clean_tweets))
  
  #clean_tweets = sapply(tweets, function(x) x$getText())
  # remove retweet entities
  clean_tweets = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', clean_tweets)
  # remove at people
  clean_tweets = gsub('@\\w+', '', clean_tweets)
  # remove punctuation
  clean_tweets = gsub('[[:punct:]]', '', clean_tweets)
  # remove numbers
  clean_tweets = gsub('[[:digit:]]', '', clean_tweets)
  # remove html links
  clean_tweets = gsub('http\\w+', '', clean_tweets)
  # remove unnecessary spaces
  clean_tweets = gsub('[ \t]{2,}', '', clean_tweets)
  clean_tweets = gsub('^\\s+|\\s+$', '', clean_tweets)
  # remove emojis or special characters
  clean_tweets = gsub('<.*>', '', enc2native(clean_tweets))
  
  clean_muslim_tweets = tolower(clean_tweets)

write.csv(clean_muslim_tweets, file="clean_muslim_tweets.csv")

```


```{r, eval= FALSE, message=FALSE}

tweets <- read.csv("christian_tweets.csv")
  clean_tweets = tweets$text
  
  print(length(clean_tweets))
  
  #clean_tweets = sapply(tweets, function(x) x$getText())
  # remove retweet entities
  clean_tweets = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', clean_tweets)
  # remove at people
  clean_tweets = gsub('@\\w+', '', clean_tweets)
  # remove punctuation
  clean_tweets = gsub('[[:punct:]]', '', clean_tweets)
  # remove numbers
  clean_tweets = gsub('[[:digit:]]', '', clean_tweets)
  # remove html links
  clean_tweets = gsub('http\\w+', '', clean_tweets)
  # remove unnecessary spaces
  clean_tweets = gsub('[ \t]{2,}', '', clean_tweets)
  clean_tweets = gsub('^\\s+|\\s+$', '', clean_tweets)
  # remove emojis or special characters
  clean_tweets = gsub('<.*>', '', enc2native(clean_tweets))
  
  clean_christian_tweets = tolower(clean_tweets)

write.csv(clean_christian_tweets, file="clean_christian_tweets.csv")
  #clean_tweets
```

# Word Cloud
```{r}
tweet_df_muslim<-read.csv("clean_muslim_tweets.csv")
# dim(tweet_df_muslim)
muslim_corpus <- Corpus(VectorSource(tweet_df_muslim$x))
muslim_corpus <- tm_map(muslim_corpus, function(x)removeWords(x,stopwords()))
# inspect(muslim_corpus)


tweet_df_christian<-read.csv("clean_christian_tweets.csv")
# dim(tweet_db_christian)
christian_corpus <- Corpus(VectorSource(tweet_df_christian$x))
christian_corpus <- tm_map(christian_corpus, function(x)removeWords(x,stopwords()))
# inspect(christian_corpus)


library("wordcloud")
# #generate wordcloud
wordcloud(muslim_corpus,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
wordcloud(christian_corpus,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
```

#Sentiment Analysis
```{r}
tweet_df_muslim$x <- as.character(tweet_df_muslim$x)
muslim_text<- tweet_df_muslim$x
#getting emotions using in-built function
sentiment_muslim<-get_nrc_sentiment((muslim_text))

#calculationg total score for each sentiment
Sentimentscores_muslim<-data.frame(colSums(sentiment_muslim[,]))

names(Sentimentscores_muslim)<-"Score"
Sentimentscores_muslim<-cbind("sentiment"=rownames(Sentimentscores_muslim),Sentimentscores_muslim)
rownames(Sentimentscores_muslim)<-NULL

ggplot(data=Sentimentscores_muslim,aes(x=sentiment,y=Score))+geom_bar(aes(fill=sentiment),stat = "identity")+
  theme(legend.position="none")+
  xlab("Sentiments")+ylab("scores")+ggtitle("Sentiments of people behind the tweets on Muslim")



tweet_df_christian$x <- as.character(tweet_df_christian$x) 
christian_text<- tweet_df_christian$x
#getting emotions using in-built function
sentiment_christian<-get_nrc_sentiment((christian_text))

#calculationg total score for each sentiment
Sentimentscores_christian<-data.frame(colSums(sentiment_christian[,]))

names(Sentimentscores_christian)<-"Score"
Sentimentscores_christian<-cbind("sentiment"=rownames(Sentimentscores_christian),Sentimentscores_christian)
rownames(Sentimentscores_christian)<-NULL

ggplot(data=Sentimentscores_christian,aes(x=sentiment,y=Score))+geom_bar(aes(fill=sentiment),stat = "identity")+
  theme(legend.position="none")+
  xlab("Sentiments")+ylab("scores")+ggtitle("Sentiments of people behind the tweets on Christian")


```



# Emotion Plot

```{r, eval= FALSE, message=FALSE}
  
emotions <- get_nrc_sentiment(clean_christian_tweets)
emo_bar = colSums(emotions)
emo_sum = data.frame(count=emo_bar, emotion=names(emo_bar))
emo_sum$emotion = factor(emo_sum$emotion, levels=emo_sum$emotion[order(emo_sum$count, decreasing = TRUE)])

emo_sum <- emo_sum[1:8,]
emo_sum$percent<-(emo_sum$count/sum(emo_sum$count))*100
  
   #Visualize the emotions from NRC sentiments
plot_ly(emo_sum, x=~emotion, y=~percent, type="bar", color=~emotion) %>%
layout(xaxis=list(title=""),  yaxis = list(title = "Emotion count"),
showlegend=FALSE,title="Distribution of emotion categories") %>%
layout(yaxis = list(ticksuffix = "%"))
``` 

